{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "functional-convert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "#from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cooked-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "focused-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = r'F:\\\\GAIT RECOGNITION\\\\90degreegei\\\\test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "general-extra",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 248 images belonging to 124 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "height=240\n",
    "width=240\n",
    "batch_size=32\n",
    "\n",
    "\n",
    "# Test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(test_dir, \n",
    "                                                  target_size=(height,width), \n",
    "                                                  batch_size=batch_size,\n",
    "                                                  color_mode='grayscale',\n",
    "                                                  shuffle = False,\n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "prerequisite-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "victorian-titanium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 12s 2s/step - loss: 0.3859 - acc: 0.9637\n",
      "[0.38593294098973274, 0.96370965]\n"
     ]
    }
   ],
   "source": [
    "test_acc = model.evaluate(test_generator,verbose=1)                  \n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-disposal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "international-offering",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fossil-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 images belonging to 124 classes.\n",
      "[  0   0   1  44   2   2   3   3  18   4   5   5   6   6   7   7   8   8\n",
      "   9   9  10  10  11  11  12  12  13  13  14  14  15  15  16  16  17  17\n",
      "  18  18  19  19  20  20  21  21  22  22  23  23  24  24  25  25  26  26\n",
      "  27  27  28  28  29  29  30  30  31  31  32 119  33  33  34  34  35  35\n",
      "  36  36  37  37  38  38  39  39  56  40  41  41  42  42  43  43  44  44\n",
      "  45  45  46  46  47  47  48  48  49  49  50  50  51  51  52  52  53  53\n",
      "  54  54  92  55  56  56  57  57  58  58  59  59  62  60  61  61  62  62\n",
      "  63  63  64  64  65  65  66  66  67  67  68  68  69  69  70  70  71  71\n",
      "  72  72  73  73  74  74  75  75  76  76  77  77  78  78  79  79  80  80\n",
      "  81  81  82  82  83  83  84  84  85  85  86  86  87  87  88  88  89  89\n",
      "  72  90  91  91  92  92  93  93  25  94  95  95  96  96  97  97  98  98\n",
      "  99  99 100 100 101 101 102 102 103 103 104 104 105 105 106 106 107 107\n",
      " 108 108 109 109 110 110 111 111 112 112 113 113 114 114 115 115 116 116\n",
      " 117 117 118 118 119  92 120 120 121 121 122 122 123 123]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_dir = r'F:\\\\GAIT RECOGNITION\\\\90degreegei\\\\train'\n",
    "\n",
    "\n",
    "# Training generator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                    target_size=(height,width),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    color_mode='grayscale',\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n",
    "predicted_class_indices=np.argmax(preds,axis=1)\n",
    "print(predicted_class_indices)\n",
    "\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "enclosed-edwards",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['001\\\\001-nm-05-090.png', '001\\\\001-nm-06-090.png', '002\\\\002-nm-05-090.png', '002\\\\002-nm-06-090.png', '003\\\\003-nm-05-090.png', '003\\\\003-nm-06-090.png', '004\\\\004-nm-05-090.png', '004\\\\004-nm-06-090.png', '005\\\\005-nm-05-090.png', '005\\\\005-nm-06-090.png', '006\\\\006-nm-05-090.png', '006\\\\006-nm-06-090.png', '007\\\\007-nm-05-090.png', '007\\\\007-nm-06-090.png', '008\\\\008-nm-05-090.png', '008\\\\008-nm-06-090.png', '009\\\\009-nm-05-090.png', '009\\\\009-nm-06-090.png', '010\\\\010-nm-05-090.png', '010\\\\010-nm-06-090.png', '011\\\\011-nm-05-090.png', '011\\\\011-nm-06-090.png', '012\\\\012-nm-05-090.png', '012\\\\012-nm-06-090.png', '013\\\\013-nm-05-090.png', '013\\\\013-nm-06-090.png', '014\\\\014-nm-05-090.png', '014\\\\014-nm-06-090.png', '015\\\\015-nm-05-090.png', '015\\\\015-nm-06-090.png', '016\\\\016-nm-05-090.png', '016\\\\016-nm-06-090.png', '017\\\\017-nm-05-090.png', '017\\\\017-nm-06-090.png', '018\\\\018-nm-05-090.png', '018\\\\018-nm-06-090.png', '019\\\\019-nm-05-090.png', '019\\\\019-nm-06-090.png', '020\\\\020-nm-05-090.png', '020\\\\020-nm-06-090.png', '021\\\\021-nm-05-090.png', '021\\\\021-nm-06-090.png', '022\\\\022-nm-05-090.png', '022\\\\022-nm-06-090.png', '023\\\\023-nm-05-090.png', '023\\\\023-nm-06-090.png', '024\\\\024-nm-05-090.png', '024\\\\024-nm-06-090.png', '025\\\\025-nm-05-090.png', '025\\\\025-nm-06-090.png', '026\\\\026-nm-05-090.png', '026\\\\026-nm-06-090.png', '027\\\\027-nm-05-090.png', '027\\\\027-nm-06-090.png', '028\\\\028-nm-05-090.png', '028\\\\028-nm-06-090.png', '029\\\\029-nm-05-090.png', '029\\\\029-nm-06-090.png', '030\\\\030-nm-05-090.png', '030\\\\030-nm-06-090.png', '031\\\\031-nm-05-090.png', '031\\\\031-nm-06-090.png', '032\\\\032-nm-05-090.png', '032\\\\032-nm-06-090.png', '033\\\\033-nm-05-090.png', '033\\\\033-nm-06-090.png', '034\\\\034-nm-05-090.png', '034\\\\034-nm-06-090.png', '035\\\\035-nm-05-090.png', '035\\\\035-nm-06-090.png', '036\\\\036-nm-05-090.png', '036\\\\036-nm-06-090.png', '037\\\\037-nm-05-090.png', '037\\\\037-nm-06-090.png', '038\\\\038-nm-05-090.png', '038\\\\038-nm-06-090.png', '039\\\\039-nm-05-090.png', '039\\\\039-nm-06-090.png', '040\\\\040-nm-05-090.png', '040\\\\040-nm-06-090.png', '041\\\\041-nm-05-090.png', '041\\\\041-nm-06-090.png', '042\\\\042-nm-05-090.png', '042\\\\042-nm-06-090.png', '043\\\\043-nm-05-090.png', '043\\\\043-nm-06-090.png', '044\\\\044-nm-05-090.png', '044\\\\044-nm-06-090.png', '045\\\\045-nm-05-090.png', '045\\\\045-nm-06-090.png', '046\\\\046-nm-05-090.png', '046\\\\046-nm-06-090.png', '047\\\\047-nm-05-090.png', '047\\\\047-nm-06-090.png', '048\\\\048-nm-05-090.png', '048\\\\048-nm-06-090.png', '049\\\\049-nm-05-090.png', '049\\\\049-nm-06-090.png', '050\\\\050-nm-05-090.png', '050\\\\050-nm-06-090.png', '051\\\\051-nm-05-090.png', '051\\\\051-nm-06-090.png', '052\\\\052-nm-05-090.png', '052\\\\052-nm-06-090.png', '053\\\\053-nm-05-090.png', '053\\\\053-nm-06-090.png', '054\\\\054-nm-05-090.png', '054\\\\054-nm-06-090.png', '055\\\\055-nm-05-090.png', '055\\\\055-nm-06-090.png', '056\\\\056-nm-05-090.png', '056\\\\056-nm-06-090.png', '057\\\\057-nm-05-090.png', '057\\\\057-nm-06-090.png', '058\\\\058-nm-05-090.png', '058\\\\058-nm-06-090.png', '059\\\\059-nm-05-090.png', '059\\\\059-nm-06-090.png', '060\\\\060-nm-05-090.png', '060\\\\060-nm-06-090.png', '061\\\\061-nm-05-090.png', '061\\\\061-nm-06-090.png', '062\\\\062-nm-05-090.png', '062\\\\062-nm-06-090.png', '063\\\\063-nm-05-090.png', '063\\\\063-nm-06-090.png', '064\\\\064-nm-05-090.png', '064\\\\064-nm-06-090.png', '065\\\\065-nm-05-090.png', '065\\\\065-nm-06-090.png', '066\\\\066-nm-05-090.png', '066\\\\066-nm-06-090.png', '067\\\\067-nm-05-090.png', '067\\\\067-nm-06-090.png', '068\\\\068-nm-05-090.png', '068\\\\068-nm-06-090.png', '069\\\\069-nm-05-090.png', '069\\\\069-nm-06-090.png', '070\\\\070-nm-05-090.png', '070\\\\070-nm-06-090.png', '071\\\\071-nm-05-090.png', '071\\\\071-nm-06-090.png', '072\\\\072-nm-05-090.png', '072\\\\072-nm-06-090.png', '073\\\\073-nm-05-090.png', '073\\\\073-nm-06-090.png', '074\\\\074-nm-05-090.png', '074\\\\074-nm-06-090.png', '075\\\\075-nm-05-090.png', '075\\\\075-nm-06-090.png', '076\\\\076-nm-05-090.png', '076\\\\076-nm-06-090.png', '077\\\\077-nm-05-090.png', '077\\\\077-nm-06-090.png', '078\\\\078-nm-05-090.png', '078\\\\078-nm-06-090.png', '079\\\\079-nm-05-090.png', '079\\\\079-nm-06-090.png', '080\\\\080-nm-05-090.png', '080\\\\080-nm-06-090.png', '081\\\\081-nm-05-090.png', '081\\\\081-nm-06-090.png', '082\\\\082-nm-05-090.png', '082\\\\082-nm-06-090.png', '083\\\\083-nm-05-090.png', '083\\\\083-nm-06-090.png', '084\\\\084-nm-05-090.png', '084\\\\084-nm-06-090.png', '085\\\\085-nm-05-090.png', '085\\\\085-nm-06-090.png', '086\\\\086-nm-05-090.png', '086\\\\086-nm-06-090.png', '087\\\\087-nm-05-090.png', '087\\\\087-nm-06-090.png', '088\\\\088-nm-05-090.png', '088\\\\088-nm-06-090.png', '089\\\\089-nm-05-090.png', '089\\\\089-nm-06-090.png', '090\\\\090-nm-05-090.png', '090\\\\090-nm-06-090.png', '091\\\\091-nm-05-090.png', '091\\\\091-nm-06-090.png', '092\\\\092-nm-05-090.png', '092\\\\092-nm-06-090.png', '093\\\\093-nm-05-090.png', '093\\\\093-nm-06-090.png', '094\\\\094-nm-05-090.png', '094\\\\094-nm-06-090.png', '095\\\\095-nm-05-090.png', '095\\\\095-nm-06-090.png', '096\\\\096-nm-05-090.png', '096\\\\096-nm-06-090.png', '097\\\\097-nm-05-090.png', '097\\\\097-nm-06-090.png', '098\\\\098-nm-05-090.png', '098\\\\098-nm-06-090.png', '099\\\\099-nm-05-090.png', '099\\\\099-nm-06-090.png', '100\\\\100-nm-05-090.png', '100\\\\100-nm-06-090.png', '101\\\\101-nm-05-090.png', '101\\\\101-nm-06-090.png', '102\\\\102-nm-05-090.png', '102\\\\102-nm-06-090.png', '103\\\\103-nm-05-090.png', '103\\\\103-nm-06-090.png', '104\\\\104-nm-05-090.png', '104\\\\104-nm-06-090.png', '105\\\\105-nm-05-090.png', '105\\\\105-nm-06-090.png', '106\\\\106-nm-05-090.png', '106\\\\106-nm-06-090.png', '107\\\\107-nm-05-090.png', '107\\\\107-nm-06-090.png', '108\\\\108-nm-05-090.png', '108\\\\108-nm-06-090.png', '109\\\\109-nm-05-090.png', '109\\\\109-nm-06-090.png', '110\\\\110-nm-05-090.png', '110\\\\110-nm-06-090.png', '111\\\\111-nm-05-090.png', '111\\\\111-nm-06-090.png', '112\\\\112-nm-05-090.png', '112\\\\112-nm-06-090.png', '113\\\\113-nm-05-090.png', '113\\\\113-nm-06-090.png', '114\\\\114-nm-05-090.png', '114\\\\114-nm-06-090.png', '115\\\\115-nm-05-090.png', '115\\\\115-nm-06-090.png', '116\\\\116-nm-05-090.png', '116\\\\116-nm-06-090.png', '117\\\\117-nm-05-090.png', '117\\\\117-nm-06-090.png', '118\\\\118-nm-05-090.png', '118\\\\118-nm-06-090.png', '119\\\\119-nm-05-090.png', '119\\\\119-nm-06-090.png', '120\\\\120-nm-05-090.png', '120\\\\120-nm-06-090.png', '121\\\\121-nm-05-090.png', '121\\\\121-nm-06-090.png', '122\\\\122-nm-05-090.png', '122\\\\122-nm-06-090.png', '123\\\\123-nm-05-090.png', '123\\\\123-nm-06-090.png', '124\\\\124-nm-05-090.png', '124\\\\124-nm-06-090.png']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "print(filenames)\n",
    "results=pd.DataFrame({\"Filename\":filenames,\"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-shame",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "organic-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from skimage import transform\n",
    "\n",
    "def load(filename):\n",
    "   np_image = Image.open(filename)\n",
    "   np_image = np.array(np_image).astype('float32')/255\n",
    "   np_image = transform.resize(np_image, (240, 240, 1))\n",
    "   np_image = np.expand_dims(np_image, axis=0)\n",
    "   return np_image\n",
    "\n",
    "\n",
    "toBePred = load(r'F:\\\\GAIT RECOGNITION\\\\90degreegei\\\\test\\\\121\\\\121-nm-06-090.png')\n",
    "\n",
    "single_pred = model.predict(toBePred) \n",
    "\n",
    "#print(single_pred)\n",
    "\n",
    "predicted_class_indices=np.argmax(single_pred,axis=1)\n",
    "print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-change",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
